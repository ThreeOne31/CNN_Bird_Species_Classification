{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inception_v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ThreeOne31/CNN_Bird_Species_Classification/blob/master/inception_v3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "NPV5kUYbygYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "clone github data into collab "
      ]
    },
    {
      "metadata": {
        "id": "KPLWhE2syeAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MbeleLebohang-uct/birds-data.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddqBsM2QzMJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download a pre trained model from google drive "
      ]
    },
    {
      "metadata": {
        "id": "ItDgQuMczKrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5234c15f-0be5-4d59-82c2-95658433abc9"
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#download file\n",
        "file_id = '1GIJrqTFtbaorkUBSTrWF93bOmG_vHMoc' # URL id. \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "name=downloaded['title']\n",
        "print(name)\n",
        "downloaded.GetContentFile('inception_v3_notop.h5')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inception_v3_notop.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vmQcTcprObHH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CNN feature etxraction "
      ]
    },
    {
      "metadata": {
        "id": "TH0pAC48OLpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bc9f8532-84ce-4e03-ef83-218f1df12b85"
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Aug 24 19:23:01 2018\n",
        "\n",
        "@author: Khomo\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "#import matplotlib.pyplot as plt\n",
        "#import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "#import seaborn as sns\n",
        "#from PIL import Image\n",
        "\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import Model\n",
        "\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.optimizers import RMSprop\n",
        "from tensorflow.python.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "#from tensorflow.python.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "#=========================================================================\n",
        "#                           variables\n",
        "#=========================================================================\n",
        "#base_dir='workingDIR'        #train in selected images\n",
        "base_dir ='birds-data/images' #traing on 200 classes\n",
        "class_names = np.array(os.listdir(base_dir))\n",
        "\n",
        "#-------------------------generate data--------------------------------\n",
        "#Split training and validation data by 0.8 to 0.2\n",
        "datagen = ImageDataGenerator(rescale=1./255) #,validation_split=0.2)\n",
        "\n",
        "#fetch images from base_dir in batches of 32 images\n",
        "#Returns (x,y) tuple\n",
        "train_generator=datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    #subset='training',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "#========================================================================================\n",
        "#               LOAD INCEPTION WEIGHTS\n",
        "#========================================================================================\n",
        "\n",
        "#Include top = False dont include classification layer\n",
        "local_weights_file = 'inception_v3_notop.h5'\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "#extract features set trainable to False use the original wieghts\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Mixed7 feature extraction layer  of 7x7 no bottleneck \n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x_flat = layers.Flatten()(last_output)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x_flat)\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 11788 images belonging to 200 classes.\n",
            "last layer output shape: (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lS6mrnOBzjPb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_pretrained =model.predict_generator(train_generator)\n",
        "#print(np.shape(features_pretrained))\n",
        "#print(features_pretrained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWydyp8JOT-j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function Definitions SVM part"
      ]
    },
    {
      "metadata": {
        "id": "-B3HeqytlVTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0bb440d7-325e-4e56-adf7-33e7737ce5ba"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import PIL.Image\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import cross_validation, grid_search\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "#---------------------variables---------------------\n",
        "class_names = np.array(os.listdir(base_dir))\n",
        "\n",
        "#========================================================================================\n",
        "#           SVM Training Function \n",
        "#========================================================================================\n",
        "def train_svm_classifer(features, labels, model_output_path):\n",
        "  \"\"\"\n",
        "  train_svm_classifer will train a SVM, saved the trained and SVM model and\n",
        "  report the classification performance\n",
        "\n",
        "  features: array of input features\n",
        "  labels: array of labels associated with the input features\n",
        "  model_output_path: path for storing the trained svm model\n",
        "  \"\"\"\n",
        "  \n",
        "  # save 20% of data for performance evaluation\n",
        "  X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, labels, test_size=0.2)\n",
        "  \n",
        "  #choose a linear classifier\n",
        "  clf = SVC(C=1, kernel='linear', probability=True,decision_function_shape='ovr')\n",
        "  joblib.dump(clf, model_output_path)\n",
        "  clf.fit(X_train, y_train)\n",
        "  \n",
        "  \n",
        "\n",
        "  y_predict=clf.predict(X_test)\n",
        "  \n",
        "  cm=confusion_matrix(y_test, y_predict)\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "  #print(cm)\n",
        "  plot_confusion_matrix(cm_normalized,class_names)\n",
        "  \n",
        "  labels=sorted(list(set(labels)))\n",
        "  print(\"\\nConfusion matrix:\")\n",
        "  print(\"Labels: {0}\\n\".format(\",\".join(str(labels))))\n",
        "  print(confusion_matrix(y_test, y_predict, labels= labels))\n",
        "\n",
        "  print(\"\\nClassification report:\")\n",
        "  print(classification_report(y_test, y_predict, target_names=class_names))\n",
        "  \n",
        "  \n",
        "  \n",
        "#=========================================================================================================\n",
        "#                     Confusion Matrix Plot\n",
        "#=========================================================================================================\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, cmap=plt.cm.Blues, title='Confusion matrix'):\n",
        "  \n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.\n",
        "  Normalization can be applied by setting `normalize=True`.\n",
        "  \"\"\"\n",
        "  #cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "  plt.imshow(cm, cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  #fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], '.2f'),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_9S39MG8Oqwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Classification Pass: CNN Features into SVM"
      ]
    },
    {
      "metadata": {
        "id": "OsAAKsg0iPiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "6eeb4c18-6594-4977-801c-41d3924596bd"
      },
      "cell_type": "code",
      "source": [
        "features =[] #array of features \n",
        "labels =[]   #array of labels\n",
        "\n",
        "x_y =train_generator\n",
        "for i in range(0,len(train_generator)):\n",
        "  img_batch = x_y[i]\n",
        "  batch_features=img_batch[0]  #32 distinct features \n",
        "  batch_labels=img_batch[1]  #32 distinct labes\n",
        "  #print(batch_labels)\n",
        "  #print(len(batch_labels))\n",
        "  #break\n",
        "  \n",
        "  #get feature labels pair sure this will be done better in a dict\n",
        "  for k in range(0,len(batch_features)):\n",
        "    arry_batch_features=batch_features[k]\n",
        "    flat_features =arry_batch_features.flatten()\n",
        "    features.append(flat_features)\n",
        "    #print(np.shape(flat_features))\n",
        "    #print(arry_batch_features)\n",
        "    labels.append(batch_labels[k])\n",
        "    #print(batch_labels[k])\n",
        "    \n",
        "   \n",
        "\n",
        "model_output_path='model/model.pkl'\n",
        "\n",
        "train_svm_classifer(features_pretrained, labels, model_output_path)\n",
        "   "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d1cb7b464703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel_output_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model/model.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain_svm_classifer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-763cf07f0717>\u001b[0m in \u001b[0;36mtrain_svm_classifer\u001b[0;34m(features, labels, model_output_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;31m#choose a linear classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'model/model.pkl'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6cuNmmmqqrKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a386e9fe-9865-42c7-e769-dfbb2dc1803b"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h_suP289zti3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload a trained CNN_SVM model to drive "
      ]
    },
    {
      "metadata": {
        "id": "wVPA_NNuzdqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': 'model.pkl'})\n",
        "uploaded.SetContentFile('model/model.pkl')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}